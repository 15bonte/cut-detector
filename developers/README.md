# README for developers

Here is diplayed what you need to know to improve, retrain and test all our methods. Note that you may need to install some additional libraries.

## How to generate ground truth data for training and evaluation

### Generate division movies

First, run Cut Detector on a video with both "Save cell division movies?" and "Debug mode" checked. "Save cell division movies?" will generate a .TIFF file for each cell division detected in the video. "Debug mode" will create a folder "Mitoses" in the results directory that will be used to update ground truth.

### Open video and CellCounter plugin in Fiji

Annotations are performed using Fiji and plugin CellCounter. In Fiji, open a cell division movie, just as usual. Open plugin by typing “Cell counter” in the Quick Search. Click on “Initialize” in the plugin.

### Rename categories

Create and rename categories as follows. Order is not very important, but naming is. “?” is used for categories where you are not sure of the true category. Note that these categories correspond to the ones in cut_detector/constants/annotations.py.

<img src="https://github.com/15bonte/cut-detector/blob/main/developers/images/CellCounter_categories.png">

### Annotate

One annotation should correspond to one midbody. Just select the corresponding category and click on the image. A marker will appear with the class number. If there is no mid-body, do not annotate.

<img src="https://github.com/15bonte/cut-detector/blob/main/developers/images/CellCounter_annotations.png">

It is not important on which channel you annotate, but do not make the same annotation on two different channels. If you have made a mistake, click on “Delete” to remove the last marker. If you want to remove a marker which is not the last one, move back to the frame, select “Delete mode” and the corresponding class, and click on the marker to remove it.

### Save

Once you have annotated everything, save your results with “Save markers”. Keep default name for the file. It should start by “CellCounter\_” and be a .xml file.

### Update .bin mitoses files

Before updating, run cut_detector/developers/ground_truth_generation/check_cell_counter_file.py to make sure annotations are consistent. In particular, this script may overwrite the initial .xml file if necessary.

Use cut_detector/developers/ground_truth_generation/annotations_upload.py to store ground truth data in .bin mitoses files.

## How to improve cell segmentation

Segmentation is performed using Cellpose. First, randomly extract frames from videos using cut_detector/developers/ground_truth_generation/segmentation/random_frames_extractor.py. Then use the GUI of Cellpose 2.0 to fine-tune the segmentation model. Finally, replace the current segmentation model with the new one.

## How to improve cell tracking

Tracking is not learned. To improve tracking, adjust Laptrack parameters or completely change the strategy if you want to use another method.

## How to improve cell division detection

Metaphase detection can be easily improved.

If required, contact Thomas Bonte or open an issue to ask for images used to train the current classifier.

Alternatively, you can generate you own training data.First, use TrackMate in Fiji to generate .xml tracking files. Run cut_detector/developers/ground_truth_generation/cell_division_detection/extract_images_from_xml.py to extract cell crops. Manually annotate these crops using cut_detector/developers/ground_truth_generation/cell_division_detection/extract_images_from_xml.py. Created folder can then be used to retrain our classifier with dedicated files from cut_detector/developers/training_and_evaluation/metaphase_cnn.

## How to improve midbody detection

Midbody detection and tracking are not learned. Same as cell tracking, you may adjust parameters to improve this step. Note that the accuracy of this task can be easily evaluated when uploading ground truth data to mitosis .bin files (see section "Update .bin mitoses files").

## How to improve microtubule cut detection

Same as for cell division detection, you can ask for training data. Alternatively, bridge images can be generated using cut_detector/developers/ground_truth_generation/bridges/extract_images_from_cell_counter.py. It requires both .xml files generated by CellCounter and the cell division movies.

Such images can be used to train bridge classification models, i.e. microtubule cut detection. Current strategy involves generating fake mirrored semi-images. They are generated using cut_detector/developers/ground_truth_generation/bridges/semi_images_generation/generate_semi_images.py. This script takes the bridge folder create above as data_dir input. Semi-images folder can then be used to retrain our classifier with dedicated files from cut_detector/developers/training_and_evaluation/binary_bridges_cnn.

## How to generate paper statistics

All statistics are generated from cut_detector/developers/training_and_evaluation/global_evaluation/compare_distributions.py. Two csv files are needed: manual annotations and matched Cut-Detector results (generated from the widget "Match divisions"). Both original files can be downloaded from https://github.com/15bonte/cut-detector-models/tree/main/data. In particular, make sure that: all column headers are the same; names are consistent i.e. avoid "Ctrl" for control for example.

By default, the script can be run with:

```
python compare_distributions.py --matched_csv_file "results - CutD-ALL_matched.csv" --manual_csv_file "Manual annotation - Cut_D auto comparaison ALL.csv" --save_folder "results"
```

Please refer to the file for additional arguments. Additionally, this script generates a division summary file and saves corresponding plots.

This can also be run directly from Napari, using the Distribution Comparison widget.
